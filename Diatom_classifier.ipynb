{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMIEcH6bbqtCawLlcBvjvbk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "QUtoxQ8pUgkK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "X0VBcVmd7DED",
        "outputId": "50cab719-8db9-453a-d332-726f7a714975"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-09790cad-e88c-4d9e-b2c2-8e6090462d01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-09790cad-e88c-4d9e-b2c2-8e6090462d01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2535520808.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_name = 'diatom_dataset.zip'\n",
        "\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "zip_file_path = f'/content/{zip_file_name}'\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    os.makedirs(extract_path)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_path)\n",
        "print(\"압축 해제 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZvE-6KJUbuL",
        "outputId": "6296d191-dec3-4df7-95f5-9e75589bfb14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "압축 해제 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/dataset/__MACOSX # Mac 압축시 생기는 메타데이터 제거"
      ],
      "metadata": {
        "id": "AKUkLE6-WhPm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = '/content/dataset/'\n",
        "\n",
        "all_image_paths = []\n",
        "for root, _, files in os.walk(DATASET_PATH):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg', '.jpeg')):\n",
        "            all_image_paths.append(os.path.join(root, file))\n",
        "\n",
        "# labeling\n",
        "def extract_label_from_filename(filepath):\n",
        "    filename = os.path.basename(filepath)\n",
        "    label = filename.split('_')[0]\n",
        "    return label\n",
        "\n",
        "labels = [extract_label_from_filename(p) for p in all_image_paths]\n",
        "\n",
        "print(f\"이미지 파일: {len(all_image_paths)}\")\n",
        "print(f\"클래수(종): {len(set(labels))}\")\n",
        "print(\"\\n\")\n",
        "for label, count in Counter(labels).most_common():\n",
        "    print(f\"클래스별 이미지 개수- {label}: {count}개\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCAf7OjeYwWu",
        "outputId": "cb9367ea-e05b-4913-dbd5-1e7938dda68c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이미지 파일: 674\n",
            "클래수(종): 94\n",
            "\n",
            "\n",
            "클래스별 이미지 개수- Fragilariforma nitzschioides: 12개\n",
            "클래스별 이미지 개수- Diatoma tenuis: 11개\n",
            "클래스별 이미지 개수- Fragilaria recapitellata: 11개\n",
            "클래스별 이미지 개수- Achnanthes inflata: 10개\n",
            "클래스별 이미지 개수- Geissleria cascadensis: 10개\n",
            "클래스별 이미지 개수- Fragilaria crotonensis: 10개\n",
            "클래스별 이미지 개수- Lindavia intermedia: 10개\n",
            "클래스별 이미지 개수- Fragilaria synegrotesca: 10개\n",
            "클래스별 이미지 개수- Chamaepinnularia gandrupii: 9개\n",
            "클래스별 이미지 개수- Fragilariforma bicapitata: 9개\n",
            "클래스별 이미지 개수- Geissleria acceptata: 9개\n",
            "클래스별 이미지 개수- Chamaepinnularia krasskei: 9개\n",
            "클래스별 이미지 개수- Geissleria decussis: 9개\n",
            "클래스별 이미지 개수- Fragilariforma virescens: 9개\n",
            "클래스별 이미지 개수- Fragilaria vaucheriae: 9개\n",
            "클래스별 이미지 개수- Epithemia sorex: 8개\n",
            "클래스별 이미지 개수- Geissleria kriegeri: 8개\n",
            "클래스별 이미지 개수- Amphora copulata: 8개\n",
            "클래스별 이미지 개수- Epithemia adnata: 8개\n",
            "클래스별 이미지 개수- Lindavia antiqua: 8개\n",
            "클래스별 이미지 개수- Chamaepinnularia krookii: 8개\n",
            "클래스별 이미지 개수- Amphora bicapitata: 8개\n",
            "클래스별 이미지 개수- Lindavia praetermissa: 8개\n",
            "클래스별 이미지 개수- Chamaepinnularia witkowskii: 8개\n",
            "클래스별 이미지 개수- Caloneis lewisii: 8개\n",
            "클래스별 이미지 개수- Lindavia ocellata: 7개\n",
            "클래스별 이미지 개수- Amphora ovalis: 7개\n",
            "클래스별 이미지 개수- Lindavia eriensis: 7개\n",
            "클래스별 이미지 개수- Fragilaria tenera: 7개\n",
            "클래스별 이미지 개수- Epithemia gibba: 7개\n",
            "클래스별 이미지 개수- Caloneis fusus: 7개\n",
            "클래스별 이미지 개수- Diatoma moniliformis: 7개\n",
            "클래스별 이미지 개수- Lindavia bodanica: 7개\n",
            "클래스별 이미지 개수- Amphora pediculus: 7개\n",
            "클래스별 이미지 개수- Achnanthes undulorostrata: 7개\n",
            "클래스별 이미지 개수- Anomoeoneis sphaerophora: 7개\n",
            "클래스별 이미지 개수- Achnanthes felinophila: 7개\n",
            "클래스별 이미지 개수- Fragilaria pennsylvanica: 7개\n",
            "클래스별 이미지 개수- Fragilariforma horstii: 7개\n",
            "클래스별 이미지 개수- Fragilaria socia: 7개\n",
            "클래스별 이미지 개수- Fragilariforma constricta: 7개\n",
            "클래스별 이미지 개수- Lindavia rossii: 7개\n",
            "클래스별 이미지 개수- Lindavia michiganiana: 7개\n",
            "클래스별 이미지 개수- Fragilaria amphicephaloides: 7개\n",
            "클래스별 이미지 개수- Halamphora veneta: 7개\n",
            "클래스별 이미지 개수- Halamphora subtilis: 7개\n",
            "클래스별 이미지 개수- Diatoma problematica: 7개\n",
            "클래스별 이미지 개수- Epithemia alpestris: 7개\n",
            "클래스별 이미지 개수- Anomoeoneis sculpta: 7개\n",
            "클래스별 이미지 개수- Epithemia reicheltii: 7개\n",
            "클래스별 이미지 개수- Geissleria lateropunctata: 7개\n",
            "클래스별 이미지 개수- Halamphora coffeiformis: 7개\n",
            "클래스별 이미지 개수- Anomoeoneis monoensis: 7개\n",
            "클래스별 이미지 개수- Diatoma vulgaris: 7개\n",
            "클래스별 이미지 개수- Achnanthes longboardia: 7개\n",
            "클래스별 이미지 개수- Epithemia smithii: 7개\n",
            "클래스별 이미지 개수- Lindavia radiosa: 7개\n",
            "클래스별 이미지 개수- Achnanthes tumescens: 7개\n",
            "클래스별 이미지 개수- Fragilaria mesolepta: 7개\n",
            "클래스별 이미지 개수- Halamphora oligotraphenta: 7개\n",
            "클래스별 이미지 개수- Achnanthes mauiensis: 7개\n",
            "클래스별 이미지 개수- Lindavia comensis: 7개\n",
            "클래스별 이미지 개수- Fragilariforma marylandica: 7개\n",
            "클래스별 이미지 개수- Anomoeoneis sphaerophora f. rostrata: 7개\n",
            "클래스별 이미지 개수- Chamaepinnularia mediocris: 7개\n",
            "클래스별 이미지 개수- Halamphora latecostata: 7개\n",
            "클래스별 이미지 개수- Fragilariforma polygonata: 6개\n",
            "클래스별 이미지 개수- Anomoeoneis costata: 6개\n",
            "클래스별 이미지 개수- Epithemia turgida: 6개\n",
            "클래스별 이미지 개수- Halamphora montana: 6개\n",
            "클래스별 이미지 개수- Fragilaria cyclopum: 6개\n",
            "클래스별 이미지 개수- Anomoeoneis fogedii: 6개\n",
            "클래스별 이미지 개수- Anomoeoneis capitata: 6개\n",
            "클래스별 이미지 개수- Amphora delphinea var. minor: 6개\n",
            "클래스별 이미지 개수- Geissleria punctifera: 6개\n",
            "클래스별 이미지 개수- Halamphora thumensis: 6개\n",
            "클래스별 이미지 개수- Amphora calumetica: 6개\n",
            "클래스별 이미지 개수- Geissleria ignota: 6개\n",
            "클래스별 이미지 개수- Caloneis amphisbaena: 6개\n",
            "클래스별 이미지 개수- Epithemia gibberula: 6개\n",
            "클래스별 이미지 개수- Epithemia argus: 6개\n",
            "클래스별 이미지 개수- Geissleria declivis: 6개\n",
            "클래스별 이미지 개수- Lindavia delicatula: 6개\n",
            "클래스별 이미지 개수- Diatoma ehrenbergii: 6개\n",
            "클래스별 이미지 개수- Chamaepinnularia soehrensis: 6개\n",
            "클래스별 이미지 개수- Fragilariforma acidobiontica: 6개\n",
            "클래스별 이미지 개수- Achnanthes coarctata: 5개\n",
            "클래스별 이미지 개수- Caloneis silicula: 5개\n",
            "클래스별 이미지 개수- Epithemia musculus: 5개\n",
            "클래스별 이미지 개수- Caloneis bacillum: 5개\n",
            "클래스별 이미지 개수- Halamphora normanii: 5개\n",
            "클래스별 이미지 개수- Lindavia affinis: 5개\n",
            "클래스별 이미지 개수- Chamaepinnularia hassiaca: 5개\n",
            "클래스별 이미지 개수- Amphora minutissima: 5개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_labels = sorted(list(set(labels)))\n",
        "label_to_int = {label: i for i, label in enumerate(sorted_labels)}\n",
        "int_to_label = {i: label for i, label in enumerate(sorted_labels)}\n",
        "\n",
        "int_labels = [label_to_int[label] for label in labels]\n",
        "\n",
        "\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    all_image_paths,\n",
        "    int_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=int_labels\n",
        ")\n",
        "\n",
        "print(f\"학습용 데이터 개수: {len(train_paths)}개\")\n",
        "print(f\"검증용 데이터 개수: {len(val_paths)}개\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONfyBKozl1uB",
        "outputId": "c9adb653-6487-4600-c666-186654bad7f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습용 데이터 개수: 539개\n",
            "검증용 데이터 개수: 135개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class DiatomDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.file_paths[idx]).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "train_dataset = DiatomDataset(train_paths, train_labels, transform=transform_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "val_dataset = DiatomDataset(val_paths, val_labels, transform=transform_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "Y0YntGwquFwS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "num_features = model.fc.in_features\n",
        "num_classes = len(sorted_labels)\n",
        "model.fc = nn.Linear(num_features, num_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDeqNqJywM6x",
        "outputId": "4e46049d-1a67-44f5-d41c-0a66fc79cdec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=94, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # 훈련 모드\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # 평가 모드\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] | Loss: {epoch_loss:.4f} | Val Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "print(\"\\n 학습 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDflsrb0zeU9",
        "outputId": "13c53721-9acd-4708-85ba-818f2e581c4e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] | Loss: 4.7410 | Val Accuracy: 8.89%\n",
            "Epoch [2/20] | Loss: 3.2234 | Val Accuracy: 20.74%\n",
            "Epoch [3/20] | Loss: 2.4365 | Val Accuracy: 38.52%\n",
            "Epoch [4/20] | Loss: 1.8568 | Val Accuracy: 41.48%\n",
            "Epoch [5/20] | Loss: 1.5480 | Val Accuracy: 31.85%\n",
            "Epoch [6/20] | Loss: 1.2677 | Val Accuracy: 47.41%\n",
            "Epoch [7/20] | Loss: 0.9869 | Val Accuracy: 50.37%\n",
            "Epoch [8/20] | Loss: 0.7672 | Val Accuracy: 54.07%\n",
            "Epoch [9/20] | Loss: 0.6593 | Val Accuracy: 55.56%\n",
            "Epoch [10/20] | Loss: 0.5814 | Val Accuracy: 59.26%\n",
            "Epoch [11/20] | Loss: 0.5198 | Val Accuracy: 56.30%\n",
            "Epoch [12/20] | Loss: 0.4251 | Val Accuracy: 62.22%\n",
            "Epoch [13/20] | Loss: 0.3270 | Val Accuracy: 68.89%\n",
            "Epoch [14/20] | Loss: 0.2654 | Val Accuracy: 67.41%\n",
            "Epoch [15/20] | Loss: 0.3077 | Val Accuracy: 65.19%\n",
            "Epoch [16/20] | Loss: 0.2534 | Val Accuracy: 68.89%\n",
            "Epoch [17/20] | Loss: 0.2277 | Val Accuracy: 62.96%\n",
            "Epoch [18/20] | Loss: 0.2203 | Val Accuracy: 65.93%\n",
            "Epoch [19/20] | Loss: 0.1812 | Val Accuracy: 68.15%\n",
            "Epoch [20/20] | Loss: 0.1461 | Val Accuracy: 62.22%\n",
            "\n",
            " 학습 완료!\n"
          ]
        }
      ]
    }
  ]
}